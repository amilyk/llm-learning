{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大语言模型 预测下一个词的概率分布 + 有监督的训练方式\n",
    "1. 基础语言模型的回答是和语料有关（回答是语义相似未必是答案）\n",
    "2. 指令微调的语言模型：指令调优，任务导向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM （large language model）预测是下一个token。简单单词多个转为1个token，相反复杂单词甚至一个单词拆成多个token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "def gen_gpt_messages(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    return messages\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature = 0):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=gen_gpt_messages(prompt),\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    if len(response.choices) > 0:\n",
    "        return response.choices[0].message.content\n",
    "    return \"generate answer error\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提问范式和token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature = 0):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    if len(response.choices) > 0:\n",
    "        return response.choices[0].message.content\n",
    "    return \"generate answer error\"\n",
    "\n",
    "def get_completion_and_token_count(messages, \n",
    "                                   model=\"gpt-3.5-turbo\", \n",
    "                                   temperature=0, \n",
    "                                   max_tokens=500):\n",
    "    \"\"\"\n",
    "    使用 OpenAI 的 GPT-3 模型生成聊天回复，并返回生成的回复内容以及使用的 token 数量。\n",
    "\n",
    "    参数:\n",
    "    messages: 聊天消息列表。\n",
    "    model: 使用的模型名称。默认为\"gpt-3.5-turbo\"。\n",
    "    temperature: 控制生成回复的随机性。值越大，生成的回复越随机。默认为 0。\n",
    "    max_tokens: 生成回复的最大 token 数量。默认为 500。\n",
    "\n",
    "    返回:\n",
    "    content: 生成的回复内容。\n",
    "    token_dict: 包含'prompt_tokens'、'completion_tokens'和'total_tokens'的字典，分别表示提示的 token 数量、生成的回复的 token 数量和总的 token 数量。\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    if len(response.choices) > 0:\n",
    "        result = response.choices[0].message.content\n",
    "        token_dict = {\n",
    "            'prompt_tokens':response.usage.prompt_tokens,\n",
    "            'completion_tokens':response.usage.completion_tokens,\n",
    "            'total_tokens':response.usage.total_tokens,\n",
    "        }\n",
    "        return result, token_dict\n",
    "    return \"generate answer error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不常用的词，颠倒这个词会出现错误。如果加上分词器，分解成3个token，出现问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pilpolol\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Take the letters in lollipop \\\n",
    "and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-o-p-i-l-l-o-l\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"\"\"Take the letters in \\\n",
    "l-o-l-l-i-p-o-p and reverse them\"\"\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英文输入：token为4个字符，或者3/4个单词\n",
    "\n",
    "中文输入：token为一个或半个词\n",
    "\n",
    "token为：输入和completion的输出的总和，输入越多，输出字数也就越少，比如turbo-3.5为4096\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 系统消息：向语言模型传达讯息\n",
    "+ 用户消息：模拟用户的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在大海里游游戏，\n",
      "欢快的小鲸鱼唱歌。\n",
      "尾巴翘翘摇来摇去，\n",
      "快乐永不停歇。\n",
      "\n",
      "海底花园美如画，\n",
      "小鲸鱼跳跃欢天涯。\n",
      "蓝色水波荡漾心，\n",
      "快乐在每个角落寻。\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role':'system',\n",
    "     'content':'你是一个助理，并以 Seuss 苏斯博士的风格作出回答。'},\n",
    "     {'role':'user',\n",
    "      'content':'就快乐的小鲸鱼为主题给我写一首短诗'}\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一只快乐的小鲸鱼在蔚蓝的海洋中跳跃游戏，和海底的朋友们一起分享欢笑和快乐的时光。\n"
     ]
    }
   ],
   "source": [
    "# 长度控制\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'你的所有答复只能是一句话'},    \n",
    "{'role':'user',\n",
    " 'content':'写一个关于快乐的小鲸鱼的故事'},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在大海深处有只小鲸鱼，欢快地游来游去，尾巴摆动得欢愉，快乐永远伴随着它。\n"
     ]
    }
   ],
   "source": [
    "# 以上结合\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'你是一个助理， 并以 Seuss 苏斯博士的风格作出回答，只回答一句话'},    \n",
    "{'role':'user',\n",
    " 'content':'写一个关于快乐的小鲸鱼的故事'},\n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在大海深处有一只小鲸鱼，\n",
      "它快乐地游来游去，不停歇。\n",
      "尾巴摆动，水花飞溅，\n",
      "欢乐的歌声响彻海洋。\n",
      "\n",
      "它和海豚一起跳舞，\n",
      "在阳光下闪闪发亮。\n",
      "快乐的小鲸鱼，永不疲倦，\n",
      "让每个人都感到温暖和欢欣。\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':'你是一个助理， 并以 Seuss 苏斯博士的风格作出回答。'},    \n",
    "{'role':'user', \n",
    " 'content':'就快乐的小鲸鱼为主题给我写一首短诗'},  \n",
    "] \n",
    "response, token_dict = get_completion_and_token_count(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 67, 'completion_tokens': 132, 'total_tokens': 199}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对用户查询的指令进行分类，分隔符区分指令和输出，一般用”#“，被模型认为是一个单独token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"####\"\n",
    "\n",
    "system_message=f\"\"\"\n",
    "你将获得客户服务查询。\n",
    "每个客户服务查询都将用{delimiter}字符分隔。\n",
    "将每个查询分类到一个主要类别和一个次要类别中。\n",
    "以JSON格式提供你的输出，包含以下键：primary 和 secondary。\n",
    "\n",
    "主要类别：计费（Billing）、技术支持（Technical Support）、账户管理（Account Management）或一般咨询（General Inquiry）。\n",
    "\n",
    "计费次要类别：\n",
    "取消订阅或升级（Unsubscribe or upgrade）\n",
    "添加付款方式（Add a payment method）\n",
    "收费解释（Explanation for charge）\n",
    "争议费用（Dispute a charge）\n",
    "\n",
    "技术支持次要类别：\n",
    "常规故障排除（General troubleshooting）\n",
    "设备兼容性（Device compatibility）\n",
    "软件更新（Software updates）\n",
    "\n",
    "账户管理次要类别：\n",
    "重置密码（Password reset）\n",
    "更新个人信息（Update personal information）\n",
    "关闭账户（Close account）\n",
    "账户安全（Account security）\n",
    "\n",
    "一般咨询次要类别：\n",
    "产品信息（Product information）\n",
    "定价（Pricing）\n",
    "反馈（Feedback）\n",
    "与人工对话（Speak to a human）\n",
    "\"\"\"\n",
    "\n",
    "user_message=f\"\"\"\\\n",
    "我希望你删除我所有的个人资料和所有用户数据。\"\"\"\n",
    "\n",
    "messages = [\n",
    "{'role':'system',\n",
    " 'content':system_message},\n",
    " {'role':'user',\n",
    " 'content':f\"{delimiter}{user_message}{delimiter}\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"primary\": \"账户管理\",\n",
      "    \"secondary\": \"关闭账户\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from chat_tools import get_completion_from_messages\n",
    "\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"primary\": \"General Inquiry\",\n",
      "    \"secondary\": \"Product information\"\n",
      "}####\n"
     ]
    }
   ],
   "source": [
    "user_message = f\"\"\"\\\n",
    "请告诉我更多有关你们的平板电脑的信息\"\"\"\n",
    "messages = [\n",
    "    {'role':'system',\n",
    "     'content':system_message},\n",
    "     {'role':'user',\n",
    "      'content':user_message}\n",
    "]\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-universe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
