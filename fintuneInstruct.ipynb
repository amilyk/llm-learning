{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import jsonlines\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "from lamini import Lamini\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "# from transformers import AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_tuned_dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†æ˜¯ï¼š\n",
      "{'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n",
      "{'instruction': 'What are the three primary colors?', 'input': '', 'output': 'The three primary colors are red, blue, and yellow.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat are the three primary colors?\\n\\n### Response:\\nThe three primary colors are red, blue, and yellow.'}\n",
      "{'instruction': 'Describe the structure of an atom.', 'input': '', 'output': 'An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe the structure of an atom.\\n\\n### Response:\\nAn atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.'}\n",
      "{'instruction': 'How can we reduce air pollution?', 'input': '', 'output': 'There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nHow can we reduce air pollution?\\n\\n### Response:\\nThere are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.'}\n",
      "{'instruction': 'Describe a time when you had to make a difficult decision.', 'input': '', 'output': 'I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the clientâ€™s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the teamâ€™s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the clientâ€™s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.', 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe a time when you had to make a difficult decision.\\n\\n### Response:\\nI had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the clientâ€™s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the teamâ€™s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the clientâ€™s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.'}\n"
     ]
    }
   ],
   "source": [
    "m = 5\n",
    "print(\"æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†æ˜¯ï¼š\")\n",
    "top_m = list(itertools.islice(instruction_tuned_dataset, m))\n",
    "for j in top_m:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¸¤ä¸ªå­—ç¬¦ä¸²æ¨¡æ¿ï¼šä¸€ä¸ªç”¨äºæœ‰è¾“å…¥å­—æ®µçš„æ•°æ®ç‚¹ï¼Œå¦ä¸€ä¸ªç”¨äºæ²¡æœ‰è¾“å…¥å­—æ®µçš„æ•°æ®ç‚¹\n",
    "prompt_template_with_input = \"\"\"ä¸‹é¢æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œè¾…ä»¥ä¸€ä¸ªæä¾›è¿›ä¸€æ­¥ä¸Šä¸‹æ–‡çš„è¾“å…¥ã€‚è¯·ç¼–å†™ä¸€ä¸ªèƒ½åˆç†å®Œæˆè¯·æ±‚çš„å“åº”ã€‚\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt_template_without_input = \"\"\"ä¸‹é¢æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ã€‚ç¼–å†™ä¸€ä¸ªèƒ½åˆç†å®Œæˆè¯·æ±‚çš„å“åº”ã€‚\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Reponse:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„åˆ—è¡¨ï¼Œç”¨äºå­˜æ”¾å¤„ç†åçš„æ•°æ®\n",
    "processed_data = []\n",
    "\n",
    "# å¾ªç¯éå†top_måˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´ jï¼ˆä½ æ²¡æœ‰ç»™å‡ºtop_mçš„å®šä¹‰ï¼Œæˆ‘å‡è®¾å®ƒæ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªæ•°æ®ç‚¹çš„åˆ—è¡¨ï¼‰\n",
    "for j in top_m:\n",
    "  # åˆ¤æ–­å½“å‰å…ƒç´ jçš„â€œinputâ€å­—æ®µæ˜¯å¦ä¸ºç©ºæˆ–ä¸å­˜åœ¨\n",
    "  if not j[\"input\"]:\n",
    "    # å¦‚æœâ€œinputâ€å­—æ®µä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨æ²¡æœ‰è¾“å…¥å­—æ®µçš„æ¨¡æ¿ï¼Œç”¨jä¸­çš„â€œinstructionâ€å­—æ®µå¡«å……\n",
    "    processed_prompt = prompt_template_without_input.format(instruction=j[\"instruction\"])\n",
    "  else:\n",
    "    # å¦‚æœâ€œinputâ€å­—æ®µå­˜åœ¨ä¸”éç©ºï¼Œåˆ™ä½¿ç”¨æœ‰è¾“å…¥å­—æ®µçš„æ¨¡æ¿ï¼Œç”¨jä¸­çš„â€œinstructionâ€å’Œâ€œinputâ€å­—æ®µå¡«å……\n",
    "    processed_prompt = prompt_template_with_input.format(instruction=j[\"instruction\"], input=j[\"input\"])\n",
    "\n",
    "  # åˆ›å»ºä¸€ä¸ªæ–°çš„å­—å…¸ï¼Œå…¶ä¸­â€œinputâ€å­—æ®µæ˜¯å¤„ç†åçš„æç¤ºï¼Œè€Œâ€œoutputâ€å­—æ®µæ˜¯jä¸­çš„â€œoutputâ€å­—æ®µï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°processed_dataåˆ—è¡¨ä¸­\n",
    "  processed_data.append({\"input\": processed_prompt, \"output\": j[\"output\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'ä¸‹é¢æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ã€‚ç¼–å†™ä¸€ä¸ªèƒ½åˆç†å®Œæˆè¯·æ±‚çš„å“åº”ã€‚\\n'\n",
      "          '\\n'\n",
      "          '### Instruction:\\n'\n",
      "          'What are the three primary colors?\\n'\n",
      "          '\\n'\n",
      "          '### Reponse:',\n",
      " 'output': 'The three primary colors are red, blue, and yellow.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(processed_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»¥å†™å…¥æ¨¡å¼æ‰“å¼€ä¸€ä¸ªåä¸º'alpaca_processed.jsonl'çš„jsonlæ–‡ä»¶\n",
    "with jsonlines.open(f'data/alpaca_processed.jsonl', 'w') as writer:\n",
    "    # ä½¿ç”¨writerçš„write_allæ–¹æ³•å°†processed_dataåˆ—è¡¨çš„æ‰€æœ‰å…ƒç´ å†™å…¥åˆ°jsonlæ–‡ä»¶ä¸­\n",
    "    writer.write_all(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¨¡å‹æ¯”è¾ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'output'],\n",
      "        num_rows: 52002\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_path_hf = \"lamini/alpaca\"\n",
    "dataset_hf = load_dataset(dataset_path_hf)\n",
    "print(dataset_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not instruction-tuned output (Llama 2 Base): æ¥\n",
      "\n",
      "æˆ‘çš„ç‹—ç‹—åä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾åä¸‹æ¥ã€‚\n",
      "\n",
      "æˆ‘æƒ³è¦å®ƒåä¸‹æ¥ï¼Œä½†æ˜¯å®ƒå¾ˆéš¾\n"
     ]
    }
   ],
   "source": [
    "import lamini\n",
    "lamini.api_key = \"95b701553ffa985833e95cff20d4606ca194adb5614624ce9e9a49ec4e980929\"\n",
    "non_instruct_model = Lamini(\"meta-llama/Llama-2-7b-hf\")\n",
    "non_instruct_output = non_instruct_model.generate(\"å‘Šè¯‰æˆ‘å¦‚ä½•è®­ç»ƒç‹—ç‹—åä¸‹\")\n",
    "print(\"Not instruction-tuned output (Llama 2 Base):\", non_instruct_output) # æ‰“å°å“åº”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction-tuned output (Llama 3 Base): \n",
      "How to Train a Dog to Sit\n",
      "Training a dog to sit is one of the most basic and essential commands you can teach your furry friend. It's a great way to establish communication and build trust between you and your dog. Here's a step-by-step guide on how to train a dog to sit:\n",
      "\n",
      "**Step 1: Choose a Quiet and Distraction-Free Area**\n",
      "Find a quiet area with minimal distractions where your dog can focus on you. Make sure your dog is comfortable and not feeling anxious or stressed.\n",
      "\n",
      "**Step 2: Have Treats Ready**\n",
      "Choose your dog's favorite treats and have them ready to use as rewards. You'll need small, tasty treats that your dog will love.\n",
      "\n",
      "**Step 3: Stand in Front of Your Dog**\n",
      "Stand in front of your dog and hold a treat close to their nose. Make sure your dog is looking at the treat and not at you.\n",
      "\n",
      "**Step 4: Move the Treat Up and Back**\n",
      "Slowly move the treat up and back, towards your dog's tail, while saying \"sit\" in a calm and clear voice. As you move the treat, your dog should naturally sit down to follow it.\n",
      "\n",
      "**Step 5: Reward and Praise**\n",
      "As soon as your dog's bottom touches the ground, give them the treat and praise them with positive reinforcement, such as \"good sit!\" or \"well done!\"\n",
      "\n",
      "**Step 6: Repeat the Process**\n",
      "Repeat steps 3-5 several times, so your dog starts to associate the command \"sit\" with the action of sitting down.\n",
      "\n",
      "**Step 7: Add the Hand Signal**\n",
      "Once your dog is comfortable with the verbal command, add a hand signal by making a downward motion with your hand, as if you're pushing their bottom down.\n",
      "\n",
      "**Step 8: Gradually Phase Out Treats**\n",
      "As your dog becomes more proficient in sitting, start to phase out the treats. Instead, use praise and affection as rewards.\n",
      "\n",
      "**Tips and Tricks**\n",
      "\n",
      "* Be patient and consistent when training your dog. It may take some time for them to learn.\n",
      "* Use a happy and upbeat tone of voice when giving commands.\n",
      "* Avoid pushing your dog's bottom down or forcing them to sit. This can create negative associations and make training more difficult.\n",
      "* Practice regularly to reinforce what your dog has learned.\n",
      "\n",
      "By following these steps and tips, you can train your dog to sit in no time! Remember to be patient, consistent, and positive, and you'll be well on your way to building a strong bond with your furry friend. ğŸ¾ğŸ’•\n",
      "\n",
      "How to Train a Dog to Sit\n",
      "Training a dog to sit is one of the most basic and essential commands you can teach your furry friend. It's a great way to establish communication and build trust between you and your dog. Here's a step-by-step guide on how to train a dog to sit:\n",
      "\n",
      "**Step 1: Choose a Quiet and Distraction-Free Area**\n",
      "Find a quiet area with minimal distractions where your dog can focus on you. Make sure your dog is comfortable and not feeling anxious or stressed.\n",
      "\n",
      "**Step 2: Have Treats Ready**\n",
      "Choose your dog's favorite treats and have them ready to use as rewards. You'll need small, tasty treats that your dog will love.\n",
      "\n",
      "**Step 3\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨è¯¥æ¨¡å‹ç”Ÿæˆå…³äºå¦‚ä½•è®­ç»ƒç‹—åä¸‹çš„å“åº”\n",
    "instruct_model = Lamini(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "instruct_output = instruct_model.generate(\"å‘Šè¯‰æˆ‘å¦‚ä½•è®­ç»ƒç‹—ç‹—åä¸‹\")\n",
    "print(\"instruction-tuned output (Llama 3 Base):\", instruct_output) # æ‰“å°å“åº”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting transformers==4.32.1\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/83/8d/f65f8138365462ace54458a9e164f4b28ce1141361970190eef36bdef986/transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
      "Requirement already satisfied: filelock in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from transformers==4.32.1) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from transformers==4.32.1) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from transformers==4.32.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from transformers==4.32.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from transformers==4.32.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from transformers==4.32.1) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from transformers==4.32.1) (2.32.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.32.1)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/89/bd/cc9c60a26b19ba012b141cba39c1d425994c78eb2458595caab860d7fa66/tokenizers-0.13.3-cp310-cp310-macosx_10_11_x86_64.whl (4.0 MB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from transformers==4.32.1) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from transformers==4.32.1) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.1) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.32.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from requests->transformers==4.32.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from requests->transformers==4.32.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from requests->transformers==4.32.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages (from requests->transformers==4.32.1) (2024.2.2)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.3\n",
      "    Uninstalling tokenizers-0.20.3:\n",
      "      Successfully uninstalled tokenizers-0.20.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.46.3\n",
      "    Uninstalling transformers-4.46.3:\n",
      "      Successfully uninstalled transformers-4.46.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 0.5.0 requires chroma-hnswlib==0.7.3, but you have chroma-hnswlib 0.7.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.32.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers==4.32.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„æ¨¡å—\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"EleutherAI/pythia-70m-deduped\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-70m-deduped/step3000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/llm-universe/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import transformers\n",
    "# transformers.logging.set_verbosity_debug()\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# !python -m pip install --upgrade pip\n",
    "# !python -m pip install --upgrade Pillow\n",
    "\n",
    "\n",
    "#low_cpu_mem_usage=True\n",
    "# !pip install accelerate\n",
    "#CPUåªèƒ½32ï¼Œdtype=torch.float32è€Œä¸æ˜¯16ï¼Œ\"LayerNormKernelImpl\" not implemented for 'Half'\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\",device_map='balanced',cache_dir='./cache/',torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æ¨ç†å‡½æ•°\n",
    "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
    "  # Tokenizeï¼šå°†è¾“å…¥æ–‡æœ¬è½¬æ¢ä¸ºToken IDs\n",
    "  input_ids = tokenizer.encode(\n",
    "          text,\n",
    "          return_tensors=\"pt\",  # è¿”å›PyTorchå¼ é‡\n",
    "          truncation=True,  # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œè¿›è¡Œæˆªæ–­\n",
    "          max_length=max_input_tokens  # è¾“å…¥æ–‡æœ¬çš„æœ€å¤§é•¿åº¦\n",
    "  )\n",
    "\n",
    "  # Generateï¼šä½¿ç”¨æ¨¡å‹ç”Ÿæˆè¾“å‡º\n",
    "  device = model.device  # è·å–æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰\n",
    "  generated_tokens_with_prompt = model.generate(\n",
    "    input_ids=input_ids.to(device),  # å°†è¾“å…¥æ•°æ®ç§»åˆ°ç›¸åŒçš„è®¾å¤‡\n",
    "    max_length=max_output_tokens  # è¾“å‡ºçš„æœ€å¤§é•¿åº¦\n",
    "  )\n",
    "\n",
    "  # Decodeï¼šå°†ç”Ÿæˆçš„Token IDsè§£ç å›æ–‡æœ¬\n",
    "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
    "\n",
    "  # Strip the promptï¼šç§»é™¤è¾“å‡ºä¸­çš„è¾“å…¥æ–‡æœ¬ï¼Œä»¥å¾—åˆ°çº¯ç²¹çš„å›åº”\n",
    "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
    "\n",
    "  return generated_text_answer  # è¿”å›ç”Ÿæˆçš„æ–‡æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1260\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 140\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "finetuning_dataset_path=\"lamini/lamini_docs\"\n",
    "finetuning_dataset = load_dataset(finetuning_dataset_path)\n",
    "print(finetuning_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Can Lamini generate technical documentation or user manuals for software projects?', 'answer': 'Yes, Lamini can generate technical documentation and user manuals for software projects. It uses natural language generation techniques to create clear and concise documentation that is easy to understand for both technical and non-technical users. This can save developers a significant amount of time and effort in creating documentation, allowing them to focus on other aspects of their projects.', 'input_ids': [5804, 418, 4988, 74, 6635, 7681, 10097, 390, 2608, 11595, 84, 323, 3694, 6493, 32, 4374, 13, 418, 4988, 74, 476, 6635, 7681, 10097, 285, 2608, 11595, 84, 323, 3694, 6493, 15, 733, 4648, 3626, 3448, 5978, 5609, 281, 2794, 2590, 285, 44003, 10097, 326, 310, 3477, 281, 2096, 323, 1097, 7681, 285, 1327, 14, 48746, 4212, 15, 831, 476, 5321, 12259, 247, 1534, 2408, 273, 673, 285, 3434, 275, 6153, 10097, 13, 6941, 731, 281, 2770, 327, 643, 7794, 273, 616, 6493, 15], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [5804, 418, 4988, 74, 6635, 7681, 10097, 390, 2608, 11595, 84, 323, 3694, 6493, 32, 4374, 13, 418, 4988, 74, 476, 6635, 7681, 10097, 285, 2608, 11595, 84, 323, 3694, 6493, 15, 733, 4648, 3626, 3448, 5978, 5609, 281, 2794, 2590, 285, 44003, 10097, 326, 310, 3477, 281, 2096, 323, 1097, 7681, 285, 1327, 14, 48746, 4212, 15, 831, 476, 5321, 12259, 247, 1534, 2408, 273, 673, 285, 3434, 275, 6153, 10097, 13, 6941, 731, 281, 2770, 327, 643, 7794, 273, 616, 6493, 15]}\n"
     ]
    }
   ],
   "source": [
    "test_sample = finetuning_dataset[\"test\"][0]\n",
    "print(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I have a question about the following:\n",
      "\n",
      "How do I get the correct documentation to work?\n",
      "\n",
      "A:\n",
      "\n",
      "I think you need to use the following code:\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the following code to get the correct documentation.\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the following code to get the correct documentation.\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the following\n"
     ]
    }
   ],
   "source": [
    "print(inference(test_sample[\"question\"], model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, Lamini can generate technical documentation or user manuals for software projects. This can be achieved by providing a prompt for a specific technical question or question to the LLM Engine, or by providing a prompt for a specific technical question or question. Additionally, Lamini can be trained on specific technical questions or questions to help users understand the process and provide feedback to the LLM Engine. Additionally, Lamini\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½å¾®è°ƒåçš„æ¨¡å‹\n",
    "instruction_model = AutoModelForCausalLM.from_pretrained(\"lamini/lamini_docs_finetuned\")\n",
    "# ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ¨ç†\n",
    "print(inference(test_sample[\"question\"], instruction_model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-universe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
